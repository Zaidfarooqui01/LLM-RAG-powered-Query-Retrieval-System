# LLM-RAG-powered-Query-Retrieval-System
Intelligent Query-Retrieval System. A FastAPI-based RAG service that ingests policy PDFs/DOCX/EML, chunks and embeds content with FAISS, and answers natural-language questions using GPT-4. Features bearer-token auth,  production-ready logging/error handling. Ready for local and Docker deployment.
